import streamlit as st
import pandas as pd
import requests
import os
from urllib.parse import quote
import io

st.set_page_config(page_title="Beauty Lens", layout="wide")

st.markdown("<h1 style='text-align: left; color: #FF69B4;'>Beauty Lens</h1>", unsafe_allow_html=True)

query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ìž…ë ¥í•˜ì„¸ìš”:", "")

def fetch_all_product_data(query):
    encoded_query = quote(query)
    base_url = "https://www.hwahae.co.kr/_next/data/MgkRfo8mFXRFxum_el3Tb/search.json"

    headers = {
        "accept": "*/*",
        "referer": f"https://www.hwahae.co.kr/search?q={encoded_query}",
        "user-agent": "Mozilla/5.0",
        "x-nextjs-data": "1",
    }

    cookies = {
        "_tt_enable_cookie": "1",
        "_ttp": "01JN5J6H0VYVFQY17YEXJCQF65_.tt.2",
        "_ga": "GA1.1.1064689440.1740722358",
    }

    all_products = []
    offset = 0
    limit = 20
    total_count = 1

    while offset < total_count:
        params = {"q": query, "type": "products", "offset": offset, "limit": limit}
        response = requests.get(base_url, headers=headers, cookies=cookies, params=params)

        if response.status_code != 200:
            return []

        data = response.json()
        
        try:
            products_data = data["pageProps"]["products"]
            products = products_data["products"]
            pagination_info = products_data["meta"]["pagination"]
            total_count = pagination_info["total_count"]
        except KeyError:
            return []

        if not products:
            break

        all_products.extend(products)
        offset += limit

    return all_products

def convert_df_to_csv(df):
    """
    ë°ì´í„°í”„ë ˆìž„ì„ CSV ë°”ì´ë„ˆë¦¬ íŒŒì¼ë¡œ ë³€í™˜í•˜ì—¬ ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•˜ê²Œ í•¨
    """
    output = io.BytesIO()
    df.to_csv(output, index=False, encoding="utf-8-sig")
    output.seek(0)
    return output

if query:
    products = fetch_all_product_data(query)

    if products:
        st.subheader(f"ðŸ”Ž '{query}' ê²€ìƒ‰ ê²°ê³¼")

        df = pd.DataFrame(products)

        df = df.drop(columns=["uid"], errors="ignore")

        df.rename(columns={
            "reviewCount": "ë¦¬ë·° ìˆ˜",
            "avgRatings": "ë³„ì ",
            "buyInfo": "êµ¬ë§¤ì •ë³´",
            "product_capacity": "ìš©ëŸ‰",
            "product_price": "ê°€ê²©"
        }, inplace=True)

        # ðŸ“¥ CSV ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ (ìœ„ìª½ìœ¼ë¡œ ë°°ì¹˜)
        csv_file = convert_df_to_csv(df)
        st.download_button(
            label="ðŸ“¥ CSVë¡œ ì €ìž¥",
            data=csv_file,
            file_name=f"{query}.csv",
            mime="text/csv",
        )

        # âœ… ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ í‘œì‹œ
        for index, row in df.iterrows():
            with st.container():
                col1, col2 = st.columns([2, 5])

                with col1:
                    st.image(row["imageUrl"], width=200)

                with col2:
                    st.write(f"### {row['productName']}")
                    st.write(f"â­ **ë³„ì  {row['ë³„ì ']}** | ðŸ“ ë¦¬ë·° {row['ë¦¬ë·° ìˆ˜']}ê°œ")
                    st.write(f"ðŸ’° **ê°€ê²©**: {row['ê°€ê²©']}ì› | ðŸ“¦ **ìš©ëŸ‰**: {row['ìš©ëŸ‰']}")
                    st.write(f"ðŸ›’ **êµ¬ë§¤ì •ë³´**: {row['êµ¬ë§¤ì •ë³´']}")

                    if "id" in row:
                        product_link = f"https://www.hwahae.co.kr/products/{row['id']}"
                        st.markdown(f"[ðŸ”— ì œí’ˆ ìƒì„¸íŽ˜ì´ì§€ ë°”ë¡œê°€ê¸°]({product_link})", unsafe_allow_html=True)
                    else:
                        st.warning("âš  ì œí’ˆ IDê°€ ì—†ì–´ ìƒì„¸íŽ˜ì´ì§€ ë§í¬ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    
                    st.write("---")

    else:
        st.warning("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
